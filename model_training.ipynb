{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be3fe9be-ee5f-445d-bc89-25c9ca527966",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82945c2d-e9ec-48a8-9f4a-0915742db169",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import boto3\n",
    "from io import BytesIO, StringIO\n",
    "from botocore.exceptions import NoCredentialsError, ClientError\n",
    "import seaborn as sns\n",
    "import time\n",
    "import warnings\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.classification import (\n",
    "    LogisticRegression,\n",
    "    RandomForestClassifier,\n",
    "    GBTClassifier,\n",
    "    DecisionTreeClassifier\n",
    ")\n",
    "\n",
    "# For Pipeline and Feature Transformation\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.ml.feature import (\n",
    "    VectorAssembler,\n",
    "    StringIndexer,\n",
    "    OneHotEncoder,\n",
    "    StandardScaler,\n",
    "    MinMaxScaler,\n",
    "    RobustScaler\n",
    ")\n",
    "\n",
    "# For Model Evaluation\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "\n",
    "# For SQL and DataFrame Operations\n",
    "from pyspark.sql.functions import col, monotonically_increasing_id\n",
    "from pyspark.sql.types import DoubleType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56e88f79-471d-4a49-ba73-0fc34ca57404",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d32d20-21e0-42f0-8902-f63d6e07f768",
   "metadata": {},
   "source": [
    "## Create SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d686e58c-3b77-4088-bbb2-eebe5e97f791",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/01/10 01:40:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Classification\") \\\n",
    "    .config(\"spark.executor.memory\", \"16g\") \\\n",
    "    .config(\"spark.driver.memory\", \"16g\") \\\n",
    "    .config(\"spark.memory.offHeap.enabled\", True) \\\n",
    "    .config(\"spark.memory.offHeap.size\", \"2g\") \\\n",
    "    .config(\"spark.executor.cores\", \"2\") \\\n",
    "    .config(\"spark.task.maxFailures\", \"4\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "117783be-826b-41c0-a289-936aaecddc7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2514707f-cca7-4619-b2a7-629971bafa29",
   "metadata": {},
   "source": [
    "## Extract Historical Data from S3 Bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eff5b0b",
   "metadata": {},
   "source": [
    "Defines a function `read_csv_from_s3_as_df` to fetch a CSV file from the specified S3 bucket and key, reads its contents into a pandas DataFrame, and prints the DataFrame or an error message if retrieval or parsing fails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03ce9ea2-fa3f-4182-9aa1-caf00acd0f6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         flightdate  day_of_week          airline tail_number dep_airport  \\\n",
      "0        2023-01-02            1     Endeavor Air      N605LR         BDL   \n",
      "1        2023-01-03            2     Endeavor Air      N605LR         BDL   \n",
      "2        2023-01-04            3     Endeavor Air      N331PQ         BDL   \n",
      "3        2023-01-05            4     Endeavor Air      N906XJ         BDL   \n",
      "4        2023-01-06            5     Endeavor Air      N337PQ         BDL   \n",
      "...             ...          ...              ...         ...         ...   \n",
      "6743368  2023-12-31            7  JetBlue Airways      N903JB         SJU   \n",
      "6743369  2023-12-31            7  JetBlue Airways      N535JB         MCO   \n",
      "6743370  2023-12-31            7  JetBlue Airways      N354JB         PHL   \n",
      "6743371  2023-12-31            7  JetBlue Airways      N768JB         PBI   \n",
      "6743372  2023-12-31            7  JetBlue Airways      N547JB         BDL   \n",
      "\n",
      "                           dep_cityname deptime_label  dep_delay  \\\n",
      "0                          Hartford, CT       Morning         -3   \n",
      "1                          Hartford, CT       Morning         -5   \n",
      "2                          Hartford, CT       Morning         -5   \n",
      "3                          Hartford, CT       Morning         -6   \n",
      "4                          Hartford, CT       Morning         -1   \n",
      "...                                 ...           ...        ...   \n",
      "6743368                    San Juan, PR       Morning          4   \n",
      "6743369                     Orlando, FL       Evening        113   \n",
      "6743370                Philadelphia, PA     Afternoon        -11   \n",
      "6743371  West Palm Beach/Palm Beach, FL     Afternoon         -7   \n",
      "6743372                    Hartford, CT       Morning         -8   \n",
      "\n",
      "         dep_delay_tag dep_delay_type arr_airport  \\\n",
      "0                    0      Low <5min         LGA   \n",
      "1                    0      Low <5min         LGA   \n",
      "2                    0      Low <5min         LGA   \n",
      "3                    0      Low <5min         LGA   \n",
      "4                    0      Low <5min         LGA   \n",
      "...                ...            ...         ...   \n",
      "6743368              1      Low <5min         JFK   \n",
      "6743369              1   Hight >60min         SJU   \n",
      "6743370              0      Low <5min         BOS   \n",
      "6743371              0      Low <5min         BDL   \n",
      "6743372              0      Low <5min         PBI   \n",
      "\n",
      "                           arr_cityname  arr_delay arr_delay_type  \\\n",
      "0                          New York, NY        -12      Low <5min   \n",
      "1                          New York, NY         -8      Low <5min   \n",
      "2                          New York, NY        -21      Low <5min   \n",
      "3                          New York, NY        -17      Low <5min   \n",
      "4                          New York, NY        -16      Low <5min   \n",
      "...                                 ...        ...            ...   \n",
      "6743368                    New York, NY        -33      Low <5min   \n",
      "6743369                    San Juan, PR        100   Hight >60min   \n",
      "6743370                      Boston, MA        -12      Low <5min   \n",
      "6743371                    Hartford, CT        -30      Low <5min   \n",
      "6743372  West Palm Beach/Palm Beach, FL        -24      Low <5min   \n",
      "\n",
      "         flight_duration        distance_type  delay_carrier  delay_weather  \\\n",
      "0                     56   Short Haul >1500Mi              0              0   \n",
      "1                     62   Short Haul >1500Mi              0              0   \n",
      "2                     49   Short Haul >1500Mi              0              0   \n",
      "3                     54   Short Haul >1500Mi              0              0   \n",
      "4                     50   Short Haul >1500Mi              0              0   \n",
      "...                  ...                  ...            ...            ...   \n",
      "6743368              219  Medium Haul <3000Mi              0              0   \n",
      "6743369              162   Short Haul >1500Mi              4              0   \n",
      "6743370               73   Short Haul >1500Mi              0              0   \n",
      "6743371              158   Short Haul >1500Mi              0              0   \n",
      "6743372              173   Short Haul >1500Mi              0              0   \n",
      "\n",
      "         delay_nas  delay_security  delay_lastaircraft           manufacturer  \\\n",
      "0                0               0                   0  CANADAIR REGIONAL JET   \n",
      "1                0               0                   0  CANADAIR REGIONAL JET   \n",
      "2                0               0                   0  CANADAIR REGIONAL JET   \n",
      "3                0               0                   0  CANADAIR REGIONAL JET   \n",
      "4                0               0                   0  CANADAIR REGIONAL JET   \n",
      "...            ...             ...                 ...                    ...   \n",
      "6743368          0               0                   0                 AIRBUS   \n",
      "6743369          0               0                  96                 AIRBUS   \n",
      "6743370          0               0                   0                EMBRAER   \n",
      "6743371          0               0                   0                 AIRBUS   \n",
      "6743372          0               0                   0                 AIRBUS   \n",
      "\n",
      "           model  aicraft_age  tavg  tmin  tmax  prcp  snow   wdir  wspd  \\\n",
      "0            CRJ           16   2.9  -2.1   8.3   0.0   0.0  338.0   3.2   \n",
      "1            CRJ           16   1.8  -1.6   4.4  10.7   0.0    3.0   3.6   \n",
      "2            CRJ           10   5.2   3.9   8.3   6.6   0.0    1.0   7.2   \n",
      "3            CRJ           17   6.8   3.9   7.8   0.8   0.0   14.0  13.7   \n",
      "4            CRJ           10   3.3   0.0   3.9   9.7   0.0    0.0   5.8   \n",
      "...          ...          ...   ...   ...   ...   ...   ...    ...   ...   \n",
      "6743368     A321           11  25.8  23.9  28.3   1.5   0.0   37.0   8.3   \n",
      "6743369     A320           22  12.4   6.1  18.9   0.0   0.0  325.0   5.6   \n",
      "6743370  190/195           11   6.1   2.8   8.3   0.0   0.0  286.0   9.7   \n",
      "6743371     A320           15  14.2   8.3  21.1   0.0   0.0  335.0   4.0   \n",
      "6743372     A320           22   2.7   1.7   3.9   0.0   0.0  312.0  14.0   \n",
      "\n",
      "           pres  \n",
      "0        1019.1  \n",
      "1        1015.2  \n",
      "2        1011.1  \n",
      "3        1014.8  \n",
      "4        1016.1  \n",
      "...         ...  \n",
      "6743368  1017.8  \n",
      "6743369  1023.8  \n",
      "6743370  1015.5  \n",
      "6743371  1023.3  \n",
      "6743372  1013.3  \n",
      "\n",
      "[6743373 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "def read_csv_from_s3_as_df(bucket, key):\n",
    "    try:\n",
    "        # Create an S3 client\n",
    "        s3 = boto3.client('s3')\n",
    "\n",
    "        # Get the object from S3\n",
    "        obj = s3.get_object(Bucket=bucket, Key=key)\n",
    "\n",
    "        # Read the contents of the file into a pandas DataFrame\n",
    "        df_pre_clean = pd.read_csv(BytesIO(obj['Body'].read()), header=0)\n",
    "\n",
    "        return df_pre_clean\n",
    "    except NoCredentialsError:\n",
    "        print(\"Credentials not available\")\n",
    "    except ClientError as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during DataFrame conversion: {e}\")\n",
    "\n",
    "\n",
    "bucket = 'big-data-team1-bucket'\n",
    "key = 'cleaned-data/historical_data.csv'\n",
    "historical_df = read_csv_from_s3_as_df(bucket, key)\n",
    "if historical_df is not None:\n",
    "    print(historical_df)\n",
    "else:\n",
    "    print(\"No data returned or error occurred\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9e1601",
   "metadata": {},
   "source": [
    "Defines a function `sample_flights` that samples a fixed number (`n_flights`) of flights per departure airport and date from the provided DataFrame, grouping by specified columns, and handles groups with fewer rows by enabling replacement during sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0363898-44a6-4b37-aeb3-3ad5c12eab2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sample_flights(dataframe, dep_airport_col='dep_airport', date_col='flightdate', n_flights=10):\n",
    "    dataframe[date_col] = pd.to_datetime(dataframe[date_col])\n",
    "\n",
    "    # Group by dep_airport and date\n",
    "    grouped = dataframe.groupby([dep_airport_col, date_col])\n",
    "\n",
    "    # Sample 10 flights from each group, allowing replacement if a group has fewer rows\n",
    "    sampled_data = grouped.apply(lambda x: x.sample(n=n_flights, replace=len(x) < n_flights)).reset_index(drop=True)\n",
    "\n",
    "    return sampled_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf538b4",
   "metadata": {},
   "source": [
    "Samples 10 flights per departure airport and flight date from the `historical_df` DataFrame and outputs the shape of the resulting sampled DataFrame to verify the operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0becaac-ad09-42d3-8ac4-ceecea6750f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1192190, 32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "historical_df = sample_flights(historical_df, dep_airport_col='dep_airport', date_col='flightdate', n_flights=10)\n",
    "\n",
    "# Verify the sampling\n",
    "historical_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bba699",
   "metadata": {},
   "source": [
    "Converts the Pandas DataFrame `historical_df` into a PySpark DataFrame for distributed processing and scalability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "514b7768-9057-45e3-bffe-ab1d2e102ab1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "historical_df = spark.createDataFrame(historical_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec4632b-3dc0-48e6-a89b-728e39be2b62",
   "metadata": {},
   "source": [
    "## Train Model (Classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a0cd12",
   "metadata": {},
   "source": [
    "Defines a function `prepare_data` to preprocess a PySpark DataFrame by adding an ID column, encoding categorical and target columns using label or one-hot encoding, assembling features into a vector, and applying transformations via a pipeline for training or testing datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eaa28f6b-0b38-4afe-86dc-a1c8111133b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_data(dataframe, target_column=\"label\", encoder_type=\"label\", is_train=True, fitted_pipeline=None):\n",
    "    # Add an ID column if not present\n",
    "    dataframe = dataframe.withColumn(\"id\", monotonically_increasing_id())\n",
    "\n",
    "    # Encode categorical columns\n",
    "    categorical_columns = [coll for coll, dtype in dataframe.dtypes if dtype == \"string\"]\n",
    "    stages = []\n",
    "\n",
    "    # Add encoders for categorical columns\n",
    "    for coll in categorical_columns:\n",
    "        if encoder_type == \"label\":\n",
    "            indexer = StringIndexer(inputCol=coll, outputCol=f\"{coll}_indexed\", handleInvalid=\"keep\")\n",
    "            stages.append(indexer)\n",
    "        elif encoder_type == \"onehot\":\n",
    "            indexer = StringIndexer(inputCol=coll, outputCol=f\"{coll}_indexed\", handleInvalid=\"keep\")\n",
    "            encoder = OneHotEncoder(inputCol=f\"{coll}_indexed\", outputCol=f\"{coll}_encoded\")\n",
    "            stages.append(indexer)\n",
    "            stages.append(encoder)\n",
    "\n",
    "    # Encode the target column\n",
    "    target_indexer = StringIndexer(inputCol=target_column, outputCol=\"label_indexed\", handleInvalid=\"keep\")\n",
    "    stages.append(target_indexer)\n",
    "\n",
    "    # Assemble features\n",
    "    encoded_categorical_columns = [\n",
    "        f\"{coll}_encoded\" if encoder_type == \"onehot\" else f\"{coll}_indexed\"\n",
    "        for coll in categorical_columns\n",
    "    ]\n",
    "    numeric_columns = [\n",
    "        coll for coll, dtype in dataframe.dtypes if dtype in [\"double\", \"bigint\"] and coll != target_column\n",
    "    ]\n",
    "    feature_columns = encoded_categorical_columns + numeric_columns\n",
    "    vector_assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "    stages.append(vector_assembler)\n",
    "\n",
    "    # Create a Pipeline\n",
    "    pipeline = Pipeline(stages=stages)\n",
    "\n",
    "    if is_train:\n",
    "        # Fit the pipeline on training data\n",
    "        fitted_pipeline = pipeline.fit(dataframe)\n",
    "        dataframe = fitted_pipeline.transform(dataframe)\n",
    "        return dataframe, fitted_pipeline\n",
    "    else:\n",
    "        # Use fitted pipeline for test data\n",
    "        dataframe = fitted_pipeline.transform(dataframe)\n",
    "        return dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91243585",
   "metadata": {},
   "source": [
    "Defines the `scale_data` function to scale features in training and testing datasets using the specified scaler (`standard`, `minmax`, or `robust`), returning the scaled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc4aca8c-0a89-4b9b-b69e-44e3fe6ab977",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def scale_data(X_train, X_test, scaler_type='standard'):\n",
    "    # Step 1: Choose the appropriate scaler\n",
    "    if scaler_type == 'standard':\n",
    "        scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\", withMean=True, withStd=True)\n",
    "    elif scaler_type == 'minmax':\n",
    "        scaler = MinMaxScaler(inputCol=\"features\", outputCol=\"scaled_features\")\n",
    "    elif scaler_type == 'robust':\n",
    "        scaler = RobustScaler(inputCol=\"features\", outputCol=\"scaled_features\")\n",
    "    else:\n",
    "        raise ValueError(\"Invalid scaler_type. Choose from 'standard', 'minmax', 'robust'.\")\n",
    "\n",
    "    # Step 2: Create a Pipeline\n",
    "    pipeline = Pipeline(stages=[scaler])\n",
    "\n",
    "    # Step 3: Fit the pipeline on the training data\n",
    "    pipeline_model = pipeline.fit(X_train)\n",
    "\n",
    "    # Step 4: Transform both train and test data\n",
    "    X_train_scaled = pipeline_model.transform(X_train).drop(\"features\").withColumnRenamed(\"scaled_features\", \"features\")\n",
    "    X_test_scaled = pipeline_model.transform(X_test).drop(\"features\").withColumnRenamed(\"scaled_features\", \"features\")\n",
    "\n",
    "    return X_train_scaled, X_test_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32420861",
   "metadata": {},
   "source": [
    "Defines the `evaluate_classification_models` function to train, evaluate, and save the best classification model from a given list using various metrics such as accuracy, F1 score, precision, and recall, while logging the performance results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8bb1c60-6ee8-4a63-9d5b-c8b46786337e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_classification_models(X_train, y_train, X_test, y_test, models, save_path=\"best_model\"):\n",
    "    # Combine features and labels into single DataFrames\n",
    "    train_data = X_train.join(y_train, \"id\")\n",
    "    test_data = X_test.join(y_test, \"id\")\n",
    "\n",
    "    model_results = []\n",
    "    trained_models = {}\n",
    "    best_model = None\n",
    "    best_accuracy = 0\n",
    "\n",
    "    for model in models:\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Train the model using a pipeline\n",
    "        pipeline = Pipeline(stages=[model])\n",
    "        trained_model = pipeline.fit(train_data)\n",
    "        trained_models[model.__class__.__name__] = trained_model\n",
    "\n",
    "        # Make predictions on the test dataset\n",
    "        predictions = trained_model.transform(test_data)\n",
    "\n",
    "        # Define evaluators for metrics\n",
    "        evaluator_accuracy = MulticlassClassificationEvaluator(labelCol=\"label_indexed\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "        evaluator_f1 = MulticlassClassificationEvaluator(labelCol=\"label_indexed\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "        evaluator_precision = MulticlassClassificationEvaluator(labelCol=\"label_indexed\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "        evaluator_recall = MulticlassClassificationEvaluator(labelCol=\"label_indexed\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "    \n",
    "\n",
    "        # Calculate metrics for test data\n",
    "        accuracy = evaluator_accuracy.evaluate(predictions)\n",
    "        f1_score = evaluator_f1.evaluate(predictions)\n",
    "        precision = evaluator_precision.evaluate(predictions)\n",
    "        recall = evaluator_recall.evaluate(predictions)\n",
    "        inference_time = time.time() - start_time  # Inference time in seconds\n",
    "\n",
    "        # Log results\n",
    "        print(f\"{model.__class__.__name__} is ready\")\n",
    "\n",
    "        model_results.append({\n",
    "            \"Model-Name\": model.__class__.__name__,\n",
    "            \"Test_Accuracy\": accuracy,\n",
    "            \"F1_Score\": f1_score,\n",
    "            \"Precision\": precision,\n",
    "            \"Recall\": recall,\n",
    "            \"Inference Time (ms)\": inference_time * 1000\n",
    "        })\n",
    "\n",
    "        # Update the best model\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_model = trained_model\n",
    "\n",
    "    # Save the best model\n",
    "    if best_model:\n",
    "        if not os.path.exists(save_path):\n",
    "            best_model.save(save_path)\n",
    "        print(f\"Best model saved at {save_path}\")\n",
    "\n",
    "    # Convert results to a pandas DataFrame\n",
    "    models_df = pd.DataFrame(model_results)\n",
    "    models_df = models_df.set_index(\"Model-Name\")\n",
    "\n",
    "    return models_df.sort_values(\"Test_Accuracy\", ascending=False), trained_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6d5c35",
   "metadata": {},
   "source": [
    "Defines a list of classification models, including Logistic Regression, Random Forest, Gradient-Boosted Trees, and Decision Tree classifiers, configured with specific parameters for training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec93072b-4c77-4887-acfb-c7275f01b4f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classification_models = [\n",
    "    LogisticRegression(featuresCol=\"features\", labelCol=\"label_indexed\", maxIter=10, regParam=0.01),\n",
    "\n",
    "    RandomForestClassifier(featuresCol=\"features\", labelCol=\"label_indexed\", numTrees=50, seed=42),\n",
    "\n",
    "    GBTClassifier(featuresCol=\"features\", labelCol=\"label_indexed\", maxIter=10, seed=42),\n",
    "    \n",
    "    DecisionTreeClassifier(featuresCol=\"features\", labelCol=\"label_indexed\", maxDepth=5, seed=42)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230f41c7",
   "metadata": {},
   "source": [
    "Filters the historical dataset to retain only relevant columns, sets the target column (`dep_delay_tag`) as the label by casting it to `DoubleType`, and removes the original target column to avoid duplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "225455db-88b9-45cc-8b03-056440163387",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Combine X and y into a single DataFrame\n",
    "data = historical_df.select(\n",
    "    *[col(c) for c in historical_df.columns if c not in [\n",
    "        'dep_delay', \"flightdate\", \"tail_number\", \"deptime_label\",\n",
    "        \"dep_airport\", \"dep_cityname\", \"arr_airport\", \"arr_cityname\", \"tmin\", \"tmax\", \"day_of_week\",\n",
    "        \"delay_carrier\", \"delay_nas\", \"delay_security\", \"delay_lastaircraft\", \"delay_weather\"\n",
    "    ]],  # Keep only desired columns\n",
    ").withColumn(\"label\", col(\"dep_delay_tag\").cast(DoubleType()))  # Set 'label' column as target variable\n",
    "\n",
    "# Drop the original target column to avoid duplication\n",
    "data = data.drop(\"dep_delay_tag\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73adc95",
   "metadata": {},
   "source": [
    "Splits the data into training and testing sets, applies data preparation steps (including encoding and feature assembly) on the training data using a pipeline, and transforms the test data using the fitted pipeline for consistent preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5fca9dfd-04bd-49cb-9155-a146ea8c1216",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "train_data, test_data = data.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Prepare the training data\n",
    "train_data_prepared, pipeline_model = prepare_data(train_data, target_column=\"label\", encoder_type=\"onehot\", is_train=True)\n",
    "\n",
    "# Prepare the test data using the fitted pipeline\n",
    "test_data_prepared = prepare_data(test_data, target_column=\"label\", encoder_type=\"onehot\", is_train=False, fitted_pipeline=pipeline_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21576591",
   "metadata": {},
   "source": [
    "Splits the prepared training and testing data into separate feature and label DataFrames, associating features and indexed labels with unique IDs for model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3651f689-ca94-4b39-9b3e-9034f9f46a5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split prepared data into features and labels\n",
    "X_train = train_data_prepared.select(\"id\", \"features\")\n",
    "y_train = train_data_prepared.select(\"id\", \"label_indexed\")\n",
    "\n",
    "X_test = test_data_prepared.select(\"id\", \"features\")\n",
    "y_test = test_data_prepared.select(\"id\", \"label_indexed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6329b3",
   "metadata": {},
   "source": [
    "Evaluates multiple classification models on the training and testing datasets, calculates performance metrics, and saves the best-performing model to the specified path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6450b73e-f756-4d29-83fe-1a2ca4d8145b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression is ready\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier is ready\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBTClassifier is ready\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier is ready\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at goodmodel\n"
     ]
    }
   ],
   "source": [
    "models_class_no_s, trained_no_s = evaluate_classification_models(X_train, y_train, X_test,\n",
    "                                                                 y_test, classification_models,\n",
    "                                                                 save_path=\"goodmodel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4307895",
   "metadata": {},
   "source": [
    "Displays all columns except the last one from the classification model evaluation results DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc0c7cbb-85f6-4ca3-be4a-b4a0fa2944c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test_Accuracy</th>\n",
       "      <th>F1_Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model-Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GBTClassifier</th>\n",
       "      <td>0.883290</td>\n",
       "      <td>0.876320</td>\n",
       "      <td>0.887891</td>\n",
       "      <td>0.883290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.881242</td>\n",
       "      <td>0.873269</td>\n",
       "      <td>0.887953</td>\n",
       "      <td>0.881242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.873855</td>\n",
       "      <td>0.863551</td>\n",
       "      <td>0.884591</td>\n",
       "      <td>0.873855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.873214</td>\n",
       "      <td>0.862819</td>\n",
       "      <td>0.883926</td>\n",
       "      <td>0.873214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Test_Accuracy  F1_Score  Precision    Recall\n",
       "Model-Name                                                          \n",
       "GBTClassifier                0.883290  0.876320   0.887891  0.883290\n",
       "DecisionTreeClassifier       0.881242  0.873269   0.887953  0.881242\n",
       "RandomForestClassifier       0.873855  0.863551   0.884591  0.873855\n",
       "LogisticRegression           0.873214  0.862819   0.883926  0.873214"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_class_no_s.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1e396e",
   "metadata": {},
   "source": [
    "Standardizes the feature data in `X_train` and `X_test` using the `StandardScaler`, ensuring that the features have a mean of 0 and a standard deviation of 1, and assigns the scaled datasets to `X_train_ss` and `X_test_ss`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee8e1f0f-f793-4aef-94bf-bff92f378baa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "X_train_ss, X_test_ss = scale_data(X_train, X_test, scaler_type=\"standard\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9332f6",
   "metadata": {},
   "source": [
    "Trains and evaluates the classification models using scaled feature data (`X_train_ss` and `X_test_ss`) and their corresponding labels (`y_train` and `y_test`), and displays the evaluation metrics (excluding the inference time) for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef6b8519-8f4b-476f-8abb-a5646b38f9e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression is ready\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier is ready\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBTClassifier is ready\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier is ready\n",
      "Best model saved at goodmodel_ss\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test_Accuracy</th>\n",
       "      <th>F1_Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model-Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GBTClassifier</th>\n",
       "      <td>0.883357</td>\n",
       "      <td>0.876843</td>\n",
       "      <td>0.886812</td>\n",
       "      <td>0.883357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.878302</td>\n",
       "      <td>0.869213</td>\n",
       "      <td>0.887229</td>\n",
       "      <td>0.878302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.873662</td>\n",
       "      <td>0.863511</td>\n",
       "      <td>0.883806</td>\n",
       "      <td>0.873662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.873214</td>\n",
       "      <td>0.862819</td>\n",
       "      <td>0.883926</td>\n",
       "      <td>0.873214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Test_Accuracy  F1_Score  Precision    Recall\n",
       "Model-Name                                                          \n",
       "GBTClassifier                0.883357  0.876843   0.886812  0.883357\n",
       "DecisionTreeClassifier       0.878302  0.869213   0.887229  0.878302\n",
       "RandomForestClassifier       0.873662  0.863511   0.883806  0.873662\n",
       "LogisticRegression           0.873214  0.862819   0.883926  0.873214"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_class_ss, trained_ss = evaluate_classification_models(X_train_ss, y_train, X_test_ss,\n",
    "                                                             y_test, classification_models,\n",
    "                                                             save_path=\"goodmodel_ss\")\n",
    "\n",
    "models_class_ss.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4760c6",
   "metadata": {},
   "source": [
    "Scales the training (`X_train`) and testing (`X_test`) feature data using Min-Max scaling and assigns the scaled datasets to `X_train_mm` and `X_test_mm` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa2cf787-e482-47c3-afe2-9698bea4e872",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "X_train_mm, X_test_mm = scale_data(X_train, X_test, scaler_type=\"minmax\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdef5d4",
   "metadata": {},
   "source": [
    "Trains and evaluates classification models using Min-Max scaled features (`X_train_mm` and `X_test_mm`) and their corresponding labels (`y_train` and `y_test`), saving the best model as `goodmodel_mm`, and displays the evaluation metrics excluding inference time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "537b3e46-cfa0-4624-a7b7-acf2b74c13b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression is ready\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier is ready\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBTClassifier is ready\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier is ready\n",
      "Best model saved at goodmodel_mm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test_Accuracy</th>\n",
       "      <th>F1_Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model-Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GBTClassifier</th>\n",
       "      <td>0.883478</td>\n",
       "      <td>0.876245</td>\n",
       "      <td>0.888864</td>\n",
       "      <td>0.883478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.881196</td>\n",
       "      <td>0.872927</td>\n",
       "      <td>0.888784</td>\n",
       "      <td>0.881196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.873654</td>\n",
       "      <td>0.863549</td>\n",
       "      <td>0.883645</td>\n",
       "      <td>0.873654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.873214</td>\n",
       "      <td>0.862819</td>\n",
       "      <td>0.883926</td>\n",
       "      <td>0.873214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Test_Accuracy  F1_Score  Precision    Recall\n",
       "Model-Name                                                          \n",
       "GBTClassifier                0.883478  0.876245   0.888864  0.883478\n",
       "DecisionTreeClassifier       0.881196  0.872927   0.888784  0.881196\n",
       "RandomForestClassifier       0.873654  0.863549   0.883645  0.873654\n",
       "LogisticRegression           0.873214  0.862819   0.883926  0.873214"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_class_mm, trained_mm = evaluate_classification_models(X_train_mm, y_train, X_test_mm,\n",
    "                                                             y_test, classification_models,\n",
    "                                                             save_path=\"goodmodel_mm\")\n",
    "\n",
    "models_class_mm.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa0dc66",
   "metadata": {},
   "source": [
    "Applies Robust Scaler to scale the features of training (`X_train`) and testing (`X_test`) datasets, producing scaled datasets (`X_train_rs` and `X_test_rs`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae61a819-753a-489b-a5e1-4f2df47290ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "X_train_rs, X_test_rs = scale_data(X_train, X_test, scaler_type=\"robust\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c409ab04",
   "metadata": {},
   "source": [
    "Evaluated multiple classification models with robust scaling on training and testing datasets to identify the best performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8d367997-03d7-45c5-9695-09c2b5d658d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression is ready\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier is ready\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBTClassifier is ready\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier is ready\n",
      "Best model saved at goodmodel_rs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test_Accuracy</th>\n",
       "      <th>F1_Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model-Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GBTClassifier</th>\n",
       "      <td>0.863921</td>\n",
       "      <td>0.859699</td>\n",
       "      <td>0.861033</td>\n",
       "      <td>0.863921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.860831</td>\n",
       "      <td>0.856296</td>\n",
       "      <td>0.857792</td>\n",
       "      <td>0.860831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.845382</td>\n",
       "      <td>0.831630</td>\n",
       "      <td>0.851635</td>\n",
       "      <td>0.845382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.724735</td>\n",
       "      <td>0.625055</td>\n",
       "      <td>0.765354</td>\n",
       "      <td>0.724735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Test_Accuracy  F1_Score  Precision    Recall\n",
       "Model-Name                                                          \n",
       "GBTClassifier                0.863921  0.859699   0.861033  0.863921\n",
       "DecisionTreeClassifier       0.860831  0.856296   0.857792  0.860831\n",
       "LogisticRegression           0.845382  0.831630   0.851635  0.845382\n",
       "RandomForestClassifier       0.724735  0.625055   0.765354  0.724735"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_class_rs, trained_rs = evaluate_classification_models(X_train_rs, y_train, X_test_rs,\n",
    "                                                             y_test, classification_models,\n",
    "                                                             save_path=\"goodmodel_rs\")\n",
    "\n",
    "models_class_rs.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3fe869",
   "metadata": {},
   "source": [
    "Consolidated evaluation results from all scaling techniques and sorted the models based on their test accuracy to compare performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ca4ce132-1fbc-4d9d-8b96-935548b19b6b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test_Accuracy</th>\n",
       "      <th>F1_Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Inference Time (ms)</th>\n",
       "      <th>Scaler</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model-Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GBTClassifier</th>\n",
       "      <td>0.883478</td>\n",
       "      <td>0.876245</td>\n",
       "      <td>0.888864</td>\n",
       "      <td>0.883478</td>\n",
       "      <td>90700.886726</td>\n",
       "      <td>MinMax Scaler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBTClassifier</th>\n",
       "      <td>0.883357</td>\n",
       "      <td>0.876843</td>\n",
       "      <td>0.886812</td>\n",
       "      <td>0.883357</td>\n",
       "      <td>88798.323393</td>\n",
       "      <td>Standard Scaler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBTClassifier</th>\n",
       "      <td>0.883290</td>\n",
       "      <td>0.876320</td>\n",
       "      <td>0.887891</td>\n",
       "      <td>0.883290</td>\n",
       "      <td>89242.838621</td>\n",
       "      <td>No Scaling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.881242</td>\n",
       "      <td>0.873269</td>\n",
       "      <td>0.887953</td>\n",
       "      <td>0.881242</td>\n",
       "      <td>77189.481497</td>\n",
       "      <td>No Scaling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.881196</td>\n",
       "      <td>0.872927</td>\n",
       "      <td>0.888784</td>\n",
       "      <td>0.881196</td>\n",
       "      <td>74924.170971</td>\n",
       "      <td>MinMax Scaler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.878302</td>\n",
       "      <td>0.869213</td>\n",
       "      <td>0.887229</td>\n",
       "      <td>0.878302</td>\n",
       "      <td>73110.928774</td>\n",
       "      <td>Standard Scaler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.873855</td>\n",
       "      <td>0.863551</td>\n",
       "      <td>0.884591</td>\n",
       "      <td>0.873855</td>\n",
       "      <td>141983.590841</td>\n",
       "      <td>No Scaling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.873662</td>\n",
       "      <td>0.863511</td>\n",
       "      <td>0.883806</td>\n",
       "      <td>0.873662</td>\n",
       "      <td>110478.057861</td>\n",
       "      <td>Standard Scaler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.873654</td>\n",
       "      <td>0.863549</td>\n",
       "      <td>0.883645</td>\n",
       "      <td>0.873654</td>\n",
       "      <td>111692.800522</td>\n",
       "      <td>MinMax Scaler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.873214</td>\n",
       "      <td>0.862819</td>\n",
       "      <td>0.883926</td>\n",
       "      <td>0.873214</td>\n",
       "      <td>97643.759012</td>\n",
       "      <td>No Scaling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.873214</td>\n",
       "      <td>0.862819</td>\n",
       "      <td>0.883926</td>\n",
       "      <td>0.873214</td>\n",
       "      <td>91423.361063</td>\n",
       "      <td>Standard Scaler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.873214</td>\n",
       "      <td>0.862819</td>\n",
       "      <td>0.883926</td>\n",
       "      <td>0.873214</td>\n",
       "      <td>88701.558828</td>\n",
       "      <td>MinMax Scaler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBTClassifier</th>\n",
       "      <td>0.863921</td>\n",
       "      <td>0.859699</td>\n",
       "      <td>0.861033</td>\n",
       "      <td>0.863921</td>\n",
       "      <td>89654.672384</td>\n",
       "      <td>Robust Scaler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.860831</td>\n",
       "      <td>0.856296</td>\n",
       "      <td>0.857792</td>\n",
       "      <td>0.860831</td>\n",
       "      <td>72760.992527</td>\n",
       "      <td>Robust Scaler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.845382</td>\n",
       "      <td>0.831630</td>\n",
       "      <td>0.851635</td>\n",
       "      <td>0.845382</td>\n",
       "      <td>86540.222406</td>\n",
       "      <td>Robust Scaler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.724735</td>\n",
       "      <td>0.625055</td>\n",
       "      <td>0.765354</td>\n",
       "      <td>0.724735</td>\n",
       "      <td>107932.918072</td>\n",
       "      <td>Robust Scaler</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Test_Accuracy  F1_Score  Precision    Recall  \\\n",
       "Model-Name                                                             \n",
       "GBTClassifier                0.883478  0.876245   0.888864  0.883478   \n",
       "GBTClassifier                0.883357  0.876843   0.886812  0.883357   \n",
       "GBTClassifier                0.883290  0.876320   0.887891  0.883290   \n",
       "DecisionTreeClassifier       0.881242  0.873269   0.887953  0.881242   \n",
       "DecisionTreeClassifier       0.881196  0.872927   0.888784  0.881196   \n",
       "DecisionTreeClassifier       0.878302  0.869213   0.887229  0.878302   \n",
       "RandomForestClassifier       0.873855  0.863551   0.884591  0.873855   \n",
       "RandomForestClassifier       0.873662  0.863511   0.883806  0.873662   \n",
       "RandomForestClassifier       0.873654  0.863549   0.883645  0.873654   \n",
       "LogisticRegression           0.873214  0.862819   0.883926  0.873214   \n",
       "LogisticRegression           0.873214  0.862819   0.883926  0.873214   \n",
       "LogisticRegression           0.873214  0.862819   0.883926  0.873214   \n",
       "GBTClassifier                0.863921  0.859699   0.861033  0.863921   \n",
       "DecisionTreeClassifier       0.860831  0.856296   0.857792  0.860831   \n",
       "LogisticRegression           0.845382  0.831630   0.851635  0.845382   \n",
       "RandomForestClassifier       0.724735  0.625055   0.765354  0.724735   \n",
       "\n",
       "                        Inference Time (ms)           Scaler  \n",
       "Model-Name                                                    \n",
       "GBTClassifier                  90700.886726    MinMax Scaler  \n",
       "GBTClassifier                  88798.323393  Standard Scaler  \n",
       "GBTClassifier                  89242.838621       No Scaling  \n",
       "DecisionTreeClassifier         77189.481497       No Scaling  \n",
       "DecisionTreeClassifier         74924.170971    MinMax Scaler  \n",
       "DecisionTreeClassifier         73110.928774  Standard Scaler  \n",
       "RandomForestClassifier        141983.590841       No Scaling  \n",
       "RandomForestClassifier        110478.057861  Standard Scaler  \n",
       "RandomForestClassifier        111692.800522    MinMax Scaler  \n",
       "LogisticRegression             97643.759012       No Scaling  \n",
       "LogisticRegression             91423.361063  Standard Scaler  \n",
       "LogisticRegression             88701.558828    MinMax Scaler  \n",
       "GBTClassifier                  89654.672384    Robust Scaler  \n",
       "DecisionTreeClassifier         72760.992527    Robust Scaler  \n",
       "LogisticRegression             86540.222406    Robust Scaler  \n",
       "RandomForestClassifier        107932.918072    Robust Scaler  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_class_no_s[\"Scaler\"] = \"No Scaling\"\n",
    "models_class_ss[\"Scaler\"] = \"Standard Scaler\"\n",
    "models_class_mm[\"Scaler\"] = \"MinMax Scaler\"\n",
    "models_class_rs[\"Scaler\"] = \"Robust Scaler\"\n",
    "\n",
    "\n",
    "all_models = pd.concat([models_class_no_s, models_class_ss, models_class_mm, models_class_rs], axis=0)\n",
    "all_models = all_models.sort_values(by=\"Test_Accuracy\", ascending=False)\n",
    "all_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477fd6a7-79ed-4b35-9b6e-decc7a473388",
   "metadata": {},
   "source": [
    "## Import Streaming Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f95487f",
   "metadata": {},
   "source": [
    "Loaded real-time data from the specified S3 bucket and key into a pandas DataFrame for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1ff5cdfd-ade3-4a79-982f-8138cddaf58f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bucket = 'big-data-team1-bucket'\n",
    "key = 'cleaned-data/realtime_data.csv'\n",
    "streaming_df = read_csv_from_s3_as_df(bucket, key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2193015",
   "metadata": {},
   "source": [
    "Converted the real-time data from a pandas DataFrame to a PySpark DataFrame for distributed processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1f6d79a2-e2e9-4747-a3e9-8b1d5cb4200a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "streaming_df = spark.createDataFrame(streaming_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a61cdf7",
   "metadata": {},
   "source": [
    "Selected relevant columns from the real-time data, excluding unnecessary features such as delay details and non-essential attributes, to prepare it for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "180d3a9c-ad10-4eba-96ed-40178737fcbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Combine X and y into a single DataFrame\n",
    "realtime_data = streaming_df.select(\n",
    "    *[col(c) for c in streaming_df.columns if c not in [\n",
    "        'dep_delay', \"flightdate\", \"tail_number\", \"deptime_label\",\n",
    "        \"dep_airport\", \"dep_cityname\", \"arr_airport\", \"arr_cityname\", \"tmin\", \"tmax\", \"day_of_week\",\n",
    "        \"delay_carrier\", \"delay_nas\", \"delay_security\", \"delay_lastaircraft\", \"delay_weather\", \"dep_delay_tag\"\n",
    "    ]],  # Keep only desired columns\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072eff1f",
   "metadata": {},
   "source": [
    "Obtained the data types of all columns in the `realtime_data` DataFrame to verify the structure and ensure compatibility for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7a76bc3d-20b7-4be4-b521-243d766c7795",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('airline', 'string'),\n",
       " ('dep_delay_type', 'string'),\n",
       " ('arr_delay', 'bigint'),\n",
       " ('arr_delay_type', 'string'),\n",
       " ('flight_duration', 'bigint'),\n",
       " ('distance_type', 'string'),\n",
       " ('manufacturer', 'string'),\n",
       " ('model', 'string'),\n",
       " ('aicraft_age', 'bigint'),\n",
       " ('tavg', 'double'),\n",
       " ('prcp', 'double'),\n",
       " ('snow', 'double'),\n",
       " ('wdir', 'double'),\n",
       " ('wspd', 'double'),\n",
       " ('pres', 'double')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "realtime_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748d8fcc",
   "metadata": {},
   "source": [
    "Added an ID column to `realtime_data`, encoded categorical columns using `StringIndexer` and `OneHotEncoder`, combined encoded and numeric columns into a feature vector using `VectorAssembler`, and applied the transformations using a pipeline, resulting in a DataFrame with `id` and `features`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7bb301f1-cbfb-454e-8808-d2c3be00c619",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------------------------------------------------------------------------------------------------+\n",
      "|id |features                                                                                                     |\n",
      "+---+-------------------------------------------------------------------------------------------------------------+\n",
      "|0  |(58,[1,2,3,6,7,8,17,25,28,31,37,42],[87.0,21.0,5.88,310.0,31.5,1022.0,1.0,1.0,1.0,1.0,1.0,1.0])              |\n",
      "|1  |(58,[0,1,2,3,6,7,8,9,17,25,28,31,37,42],[-16.0,43.0,21.0,5.88,310.0,31.5,1022.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|\n",
      "|2  |(58,[0,1,2,3,6,7,8,9,17,25,28,31,37,42],[-15.0,68.0,20.0,5.88,310.0,31.5,1022.0,2.0,1.0,1.0,1.0,1.0,1.0,1.0])|\n",
      "|3  |(58,[0,1,2,3,6,7,8,9,17,25,28,31,37,42],[-14.0,62.0,11.0,5.88,310.0,31.5,1022.0,3.0,1.0,1.0,1.0,1.0,1.0,1.0])|\n",
      "|4  |(58,[0,1,2,3,6,7,8,9,17,27,30,31,37,42],[906.0,55.0,20.0,5.88,310.0,31.5,1022.0,4.0,1.0,1.0,1.0,1.0,1.0,1.0])|\n",
      "+---+-------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "realtime_data = realtime_data.withColumn(\"id\", monotonically_increasing_id())\n",
    "\n",
    "categorical_columns = [coll for coll, dtype in realtime_data.dtypes if dtype == \"string\"]\n",
    "numeric_columns = [coll for coll, dtype in realtime_data.dtypes if dtype in [\"double\", \"bigint\"]]\n",
    "\n",
    "stages = []  # For storing transformations\n",
    "encoded_categorical_columns = []  # To store names of new indexed columns\n",
    "\n",
    "for coll in categorical_columns:\n",
    "    indexed_col = f\"{coll}_indexed\"\n",
    "    encoded_col = f\"{coll}_encoded\"\n",
    "    indexer = StringIndexer(inputCol=coll, outputCol=indexed_col, handleInvalid=\"keep\")\n",
    "    encoder = OneHotEncoder(inputCol=f\"{coll}_indexed\", outputCol=f\"{coll}_encoded\")\n",
    "    stages.append(indexer)\n",
    "    stages.append(encoder)\n",
    "    encoded_categorical_columns.append(encoded_col)  # Add to encoded column list\n",
    "\n",
    "real_feature_columns = numeric_columns + encoded_categorical_columns\n",
    "vector_assembler = VectorAssembler(inputCols=real_feature_columns, outputCol=\"features\")\n",
    "stages.append(vector_assembler)\n",
    "\n",
    "pipeline = Pipeline(stages=stages)\n",
    "pipeline_model = pipeline.fit(realtime_data)\n",
    "\n",
    "realtime_data = pipeline_model.transform(realtime_data).select(\"id\", \"features\")\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "realtime_data.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43914c12",
   "metadata": {},
   "source": [
    "Displayed the data types of the columns in `realtime_data`, which now include `id` (bigint) and `features` (vector)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "22373119-3925-45b9-ad72-8938661e9c2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('id', 'bigint'), ('features', 'vector')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "realtime_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1f3fdf",
   "metadata": {},
   "source": [
    "Loaded the saved model `goodmodel` for making predictions on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b4ef3e96-c86b-4dc4-b91a-101e1839129d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.util.SizeEstimator$ (file:/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pyspark/jars/spark-core_2.12-3.3.0.jar) to field java.math.BigInteger.mag\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.util.SizeEstimator$\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model\n",
    "loaded_model = PipelineModel.load(\"goodmodel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a22b18",
   "metadata": {},
   "source": [
    "Applied the loaded model `goodmodel` to generate predictions on the `realtime_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "80eb938d-6712-4297-9253-0cc73b6c1969",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = loaded_model.transform(realtime_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6698607",
   "metadata": {},
   "source": [
    "Displayed the schema of the `predictions` DataFrame to verify the output structure after applying the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7d463b99-97a4-4add-8381-a62abc233584",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = false)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae1ef8f",
   "metadata": {},
   "source": [
    "Displayed the top 10 rows of the `predictions` DataFrame, including the `features`, `prediction`, and `probability` columns, to analyze the model's output on the real-time data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2e080be2-0528-46bf-ad68-1d617960d9d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------------------+----------+----------------------------------------+\n",
      "|features                                                                                                      |prediction|probability                             |\n",
      "+--------------------------------------------------------------------------------------------------------------+----------+----------------------------------------+\n",
      "|(58,[1,2,3,6,7,8,17,25,28,31,37,42],[87.0,21.0,5.88,310.0,31.5,1022.0,1.0,1.0,1.0,1.0,1.0,1.0])               |1.0       |[0.07804449086734791,0.9219555091326521]|\n",
      "|(58,[0,1,2,3,6,7,8,9,17,25,28,31,37,42],[-16.0,43.0,21.0,5.88,310.0,31.5,1022.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0]) |1.0       |[0.07804449086734791,0.9219555091326521]|\n",
      "|(58,[0,1,2,3,6,7,8,9,17,25,28,31,37,42],[-15.0,68.0,20.0,5.88,310.0,31.5,1022.0,2.0,1.0,1.0,1.0,1.0,1.0,1.0]) |1.0       |[0.07804449086734791,0.9219555091326521]|\n",
      "|(58,[0,1,2,3,6,7,8,9,17,25,28,31,37,42],[-14.0,62.0,11.0,5.88,310.0,31.5,1022.0,3.0,1.0,1.0,1.0,1.0,1.0,1.0]) |1.0       |[0.07804449086734791,0.9219555091326521]|\n",
      "|(58,[0,1,2,3,6,7,8,9,17,27,30,31,37,42],[906.0,55.0,20.0,5.88,310.0,31.5,1022.0,4.0,1.0,1.0,1.0,1.0,1.0,1.0]) |1.0       |[0.0786100332068999,0.9213899667931001] |\n",
      "|(58,[0,1,2,3,6,7,8,9,17,25,28,31,37,42],[-19.0,109.0,16.0,5.88,310.0,31.5,1022.0,5.0,1.0,1.0,1.0,1.0,1.0,1.0])|1.0       |[0.07804449086734791,0.9219555091326521]|\n",
      "|(58,[0,1,2,3,6,7,8,9,17,26,28,31,37,42],[2.0,64.0,17.0,5.88,310.0,31.5,1022.0,6.0,1.0,1.0,1.0,1.0,1.0,1.0])   |1.0       |[0.07845427620336161,0.9215457237966383]|\n",
      "|(58,[0,1,2,3,6,7,8,9,17,26,30,31,37,42],[70.0,104.0,21.0,5.88,310.0,31.5,1022.0,7.0,1.0,1.0,1.0,1.0,1.0,1.0]) |1.0       |[0.07845427620336161,0.9215457237966383]|\n",
      "|(58,[0,1,2,3,6,7,8,9,17,25,28,31,37,42],[-21.0,38.0,20.0,5.88,310.0,31.5,1022.0,8.0,1.0,1.0,1.0,1.0,1.0,1.0]) |1.0       |[0.07804449086734791,0.9219555091326521]|\n",
      "|(58,[0,1,2,3,6,7,8,9,17,25,28,31,37,42],[-6.0,59.0,20.0,5.88,310.0,31.5,1022.0,9.0,1.0,1.0,1.0,1.0,1.0,1.0])  |1.0       |[0.07804449086734791,0.9219555091326521]|\n",
      "+--------------------------------------------------------------------------------------------------------------+----------+----------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select(\"features\", \"prediction\", \"probability\").show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65c846a",
   "metadata": {},
   "source": [
    "Combined the original `streaming_df` DataFrame with the `predictions` DataFrame using a common `id` column to integrate predictions into the original dataset, dropped redundant columns, and converted the final DataFrame into a Pandas DataFrame for further analysis, displaying the last 10 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9a024f0f-3535-4d2c-b160-8266ae92537c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flightdate</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>airline</th>\n",
       "      <th>tail_number</th>\n",
       "      <th>dep_airport</th>\n",
       "      <th>dep_cityname</th>\n",
       "      <th>deptime_label</th>\n",
       "      <th>dep_delay</th>\n",
       "      <th>dep_delay_type</th>\n",
       "      <th>arr_airport</th>\n",
       "      <th>arr_cityname</th>\n",
       "      <th>arr_delay</th>\n",
       "      <th>arr_delay_type</th>\n",
       "      <th>flight_duration</th>\n",
       "      <th>distance_type</th>\n",
       "      <th>delay_carrier</th>\n",
       "      <th>delay_weather</th>\n",
       "      <th>delay_nas</th>\n",
       "      <th>delay_security</th>\n",
       "      <th>delay_lastaircraft</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>model</th>\n",
       "      <th>aicraft_age</th>\n",
       "      <th>tavg</th>\n",
       "      <th>tmin</th>\n",
       "      <th>tmax</th>\n",
       "      <th>prcp</th>\n",
       "      <th>snow</th>\n",
       "      <th>wdir</th>\n",
       "      <th>wspd</th>\n",
       "      <th>pres</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42843</th>\n",
       "      <td>2025-01-13</td>\n",
       "      <td>5</td>\n",
       "      <td>Skywest Airlines Inc.</td>\n",
       "      <td>N122SY</td>\n",
       "      <td>ORD</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Morning</td>\n",
       "      <td>-3</td>\n",
       "      <td>Low &lt;5min</td>\n",
       "      <td>AUS</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>-36</td>\n",
       "      <td>Low &lt;5min</td>\n",
       "      <td>149</td>\n",
       "      <td>Short Haul &gt;1500Mi</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>EMBRAER</td>\n",
       "      <td>170/175</td>\n",
       "      <td>10</td>\n",
       "      <td>-5.73</td>\n",
       "      <td>-9.72</td>\n",
       "      <td>-1.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.05</td>\n",
       "      <td>296.0</td>\n",
       "      <td>23.40</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42844</th>\n",
       "      <td>2025-01-13</td>\n",
       "      <td>5</td>\n",
       "      <td>Skywest Airlines Inc.</td>\n",
       "      <td>N918SW</td>\n",
       "      <td>ORD</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Morning</td>\n",
       "      <td>-4</td>\n",
       "      <td>Low &lt;5min</td>\n",
       "      <td>BHM</td>\n",
       "      <td>Birmingham, AL</td>\n",
       "      <td>9</td>\n",
       "      <td>Low &lt;5min</td>\n",
       "      <td>139</td>\n",
       "      <td>Short Haul &gt;1500Mi</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CANADAIR REGIONAL JET</td>\n",
       "      <td>CRJ</td>\n",
       "      <td>22</td>\n",
       "      <td>-5.73</td>\n",
       "      <td>-9.72</td>\n",
       "      <td>-1.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.05</td>\n",
       "      <td>296.0</td>\n",
       "      <td>23.40</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42845</th>\n",
       "      <td>2025-01-13</td>\n",
       "      <td>5</td>\n",
       "      <td>United Air Lines Inc.</td>\n",
       "      <td>N815UA</td>\n",
       "      <td>ORD</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>-1</td>\n",
       "      <td>Low &lt;5min</td>\n",
       "      <td>DCA</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>8</td>\n",
       "      <td>Low &lt;5min</td>\n",
       "      <td>121</td>\n",
       "      <td>Short Haul &gt;1500Mi</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>AIRBUS</td>\n",
       "      <td>A319</td>\n",
       "      <td>26</td>\n",
       "      <td>-5.73</td>\n",
       "      <td>-9.72</td>\n",
       "      <td>-1.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.05</td>\n",
       "      <td>296.0</td>\n",
       "      <td>23.40</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42846</th>\n",
       "      <td>2025-01-15</td>\n",
       "      <td>7</td>\n",
       "      <td>American Eagle Airlines Inc.</td>\n",
       "      <td>N253NN</td>\n",
       "      <td>ORD</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Morning</td>\n",
       "      <td>-4</td>\n",
       "      <td>Low &lt;5min</td>\n",
       "      <td>OKC</td>\n",
       "      <td>Oklahoma City, OK</td>\n",
       "      <td>-18</td>\n",
       "      <td>Low &lt;5min</td>\n",
       "      <td>127</td>\n",
       "      <td>Short Haul &gt;1500Mi</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>EMBRAER</td>\n",
       "      <td>170/175</td>\n",
       "      <td>7</td>\n",
       "      <td>-5.27</td>\n",
       "      <td>-9.38</td>\n",
       "      <td>-1.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>217.0</td>\n",
       "      <td>15.84</td>\n",
       "      <td>1031.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42847</th>\n",
       "      <td>2025-01-15</td>\n",
       "      <td>7</td>\n",
       "      <td>American Eagle Airlines Inc.</td>\n",
       "      <td>N619AE</td>\n",
       "      <td>ORD</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Morning</td>\n",
       "      <td>-7</td>\n",
       "      <td>Low &lt;5min</td>\n",
       "      <td>ALO</td>\n",
       "      <td>Waterloo, IA</td>\n",
       "      <td>-17</td>\n",
       "      <td>Low &lt;5min</td>\n",
       "      <td>68</td>\n",
       "      <td>Short Haul &gt;1500Mi</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>EMBRAER</td>\n",
       "      <td>135/145</td>\n",
       "      <td>26</td>\n",
       "      <td>-5.27</td>\n",
       "      <td>-9.38</td>\n",
       "      <td>-1.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>217.0</td>\n",
       "      <td>15.84</td>\n",
       "      <td>1031.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42848</th>\n",
       "      <td>2025-01-15</td>\n",
       "      <td>7</td>\n",
       "      <td>United Air Lines Inc.</td>\n",
       "      <td>N14228</td>\n",
       "      <td>ORD</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Evening</td>\n",
       "      <td>5</td>\n",
       "      <td>Low &lt;5min</td>\n",
       "      <td>PHL</td>\n",
       "      <td>Philadelphia, PA</td>\n",
       "      <td>-5</td>\n",
       "      <td>Low &lt;5min</td>\n",
       "      <td>116</td>\n",
       "      <td>Short Haul &gt;1500Mi</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BOEING</td>\n",
       "      <td>737 NG</td>\n",
       "      <td>25</td>\n",
       "      <td>-5.27</td>\n",
       "      <td>-9.38</td>\n",
       "      <td>-1.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>217.0</td>\n",
       "      <td>15.84</td>\n",
       "      <td>1031.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42849</th>\n",
       "      <td>2025-01-15</td>\n",
       "      <td>7</td>\n",
       "      <td>United Air Lines Inc.</td>\n",
       "      <td>N873UA</td>\n",
       "      <td>ORD</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>1</td>\n",
       "      <td>Low &lt;5min</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>7</td>\n",
       "      <td>Low &lt;5min</td>\n",
       "      <td>122</td>\n",
       "      <td>Short Haul &gt;1500Mi</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>AIRBUS</td>\n",
       "      <td>A319</td>\n",
       "      <td>21</td>\n",
       "      <td>-5.27</td>\n",
       "      <td>-9.38</td>\n",
       "      <td>-1.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>217.0</td>\n",
       "      <td>15.84</td>\n",
       "      <td>1031.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42850</th>\n",
       "      <td>2025-01-14</td>\n",
       "      <td>6</td>\n",
       "      <td>Spirit Air Lines</td>\n",
       "      <td>N957NK</td>\n",
       "      <td>ORD</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Morning</td>\n",
       "      <td>-8</td>\n",
       "      <td>Low &lt;5min</td>\n",
       "      <td>LAX</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>-9</td>\n",
       "      <td>Low &lt;5min</td>\n",
       "      <td>284</td>\n",
       "      <td>Medium Haul &lt;3000Mi</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>AIRBUS</td>\n",
       "      <td>A320</td>\n",
       "      <td>2</td>\n",
       "      <td>-9.12</td>\n",
       "      <td>-11.29</td>\n",
       "      <td>-6.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>280.0</td>\n",
       "      <td>18.25</td>\n",
       "      <td>1035.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42851</th>\n",
       "      <td>2025-01-14</td>\n",
       "      <td>6</td>\n",
       "      <td>Skywest Airlines Inc.</td>\n",
       "      <td>N618UX</td>\n",
       "      <td>ORD</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Evening</td>\n",
       "      <td>7</td>\n",
       "      <td>Low &lt;5min</td>\n",
       "      <td>OKC</td>\n",
       "      <td>Oklahoma City, OK</td>\n",
       "      <td>7</td>\n",
       "      <td>Low &lt;5min</td>\n",
       "      <td>150</td>\n",
       "      <td>Short Haul &gt;1500Mi</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>EMBRAER</td>\n",
       "      <td>170/175</td>\n",
       "      <td>5</td>\n",
       "      <td>-9.12</td>\n",
       "      <td>-11.29</td>\n",
       "      <td>-6.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>280.0</td>\n",
       "      <td>18.25</td>\n",
       "      <td>1035.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42852</th>\n",
       "      <td>2025-01-14</td>\n",
       "      <td>6</td>\n",
       "      <td>United Air Lines Inc.</td>\n",
       "      <td>N803UA</td>\n",
       "      <td>ORD</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Evening</td>\n",
       "      <td>16</td>\n",
       "      <td>Medium &gt;15min</td>\n",
       "      <td>EWR</td>\n",
       "      <td>Newark, NJ</td>\n",
       "      <td>10</td>\n",
       "      <td>Low &lt;5min</td>\n",
       "      <td>129</td>\n",
       "      <td>Short Haul &gt;1500Mi</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>AIRBUS</td>\n",
       "      <td>A319</td>\n",
       "      <td>27</td>\n",
       "      <td>-9.12</td>\n",
       "      <td>-11.29</td>\n",
       "      <td>-6.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>280.0</td>\n",
       "      <td>18.25</td>\n",
       "      <td>1035.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       flightdate  day_of_week                       airline tail_number  \\\n",
       "42843  2025-01-13            5         Skywest Airlines Inc.      N122SY   \n",
       "42844  2025-01-13            5         Skywest Airlines Inc.      N918SW   \n",
       "42845  2025-01-13            5         United Air Lines Inc.      N815UA   \n",
       "42846  2025-01-15            7  American Eagle Airlines Inc.      N253NN   \n",
       "42847  2025-01-15            7  American Eagle Airlines Inc.      N619AE   \n",
       "42848  2025-01-15            7         United Air Lines Inc.      N14228   \n",
       "42849  2025-01-15            7         United Air Lines Inc.      N873UA   \n",
       "42850  2025-01-14            6              Spirit Air Lines      N957NK   \n",
       "42851  2025-01-14            6         Skywest Airlines Inc.      N618UX   \n",
       "42852  2025-01-14            6         United Air Lines Inc.      N803UA   \n",
       "\n",
       "      dep_airport dep_cityname deptime_label  dep_delay dep_delay_type  \\\n",
       "42843         ORD  Chicago, IL       Morning         -3      Low <5min   \n",
       "42844         ORD  Chicago, IL       Morning         -4      Low <5min   \n",
       "42845         ORD  Chicago, IL     Afternoon         -1      Low <5min   \n",
       "42846         ORD  Chicago, IL       Morning         -4      Low <5min   \n",
       "42847         ORD  Chicago, IL       Morning         -7      Low <5min   \n",
       "42848         ORD  Chicago, IL       Evening          5      Low <5min   \n",
       "42849         ORD  Chicago, IL     Afternoon          1      Low <5min   \n",
       "42850         ORD  Chicago, IL       Morning         -8      Low <5min   \n",
       "42851         ORD  Chicago, IL       Evening          7      Low <5min   \n",
       "42852         ORD  Chicago, IL       Evening         16  Medium >15min   \n",
       "\n",
       "      arr_airport       arr_cityname  arr_delay arr_delay_type  \\\n",
       "42843         AUS         Austin, TX        -36      Low <5min   \n",
       "42844         BHM     Birmingham, AL          9      Low <5min   \n",
       "42845         DCA     Washington, DC          8      Low <5min   \n",
       "42846         OKC  Oklahoma City, OK        -18      Low <5min   \n",
       "42847         ALO       Waterloo, IA        -17      Low <5min   \n",
       "42848         PHL   Philadelphia, PA         -5      Low <5min   \n",
       "42849         ATL        Atlanta, GA          7      Low <5min   \n",
       "42850         LAX    Los Angeles, CA         -9      Low <5min   \n",
       "42851         OKC  Oklahoma City, OK          7      Low <5min   \n",
       "42852         EWR         Newark, NJ         10      Low <5min   \n",
       "\n",
       "       flight_duration        distance_type  delay_carrier  delay_weather  \\\n",
       "42843              149   Short Haul >1500Mi              0              0   \n",
       "42844              139   Short Haul >1500Mi              0              0   \n",
       "42845              121   Short Haul >1500Mi              0              0   \n",
       "42846              127   Short Haul >1500Mi              0              0   \n",
       "42847               68   Short Haul >1500Mi              0              0   \n",
       "42848              116   Short Haul >1500Mi              0              0   \n",
       "42849              122   Short Haul >1500Mi              0              0   \n",
       "42850              284  Medium Haul <3000Mi              0              0   \n",
       "42851              150   Short Haul >1500Mi              0              0   \n",
       "42852              129   Short Haul >1500Mi              0              0   \n",
       "\n",
       "       delay_nas  delay_security  delay_lastaircraft           manufacturer  \\\n",
       "42843          0               0                   0                EMBRAER   \n",
       "42844          0               0                   0  CANADAIR REGIONAL JET   \n",
       "42845          0               0                   0                 AIRBUS   \n",
       "42846          0               0                   0                EMBRAER   \n",
       "42847          0               0                   0                EMBRAER   \n",
       "42848          0               0                   0                 BOEING   \n",
       "42849          0               0                   0                 AIRBUS   \n",
       "42850          0               0                   0                 AIRBUS   \n",
       "42851          0               0                   0                EMBRAER   \n",
       "42852          0               0                   0                 AIRBUS   \n",
       "\n",
       "         model  aicraft_age  tavg   tmin  tmax  prcp  snow   wdir   wspd  \\\n",
       "42843  170/175           10 -5.73  -9.72 -1.74   0.0  1.05  296.0  23.40   \n",
       "42844      CRJ           22 -5.73  -9.72 -1.74   0.0  1.05  296.0  23.40   \n",
       "42845     A319           26 -5.73  -9.72 -1.74   0.0  1.05  296.0  23.40   \n",
       "42846  170/175            7 -5.27  -9.38 -1.16   0.0  0.00  217.0  15.84   \n",
       "42847  135/145           26 -5.27  -9.38 -1.16   0.0  0.00  217.0  15.84   \n",
       "42848   737 NG           25 -5.27  -9.38 -1.16   0.0  0.00  217.0  15.84   \n",
       "42849     A319           21 -5.27  -9.38 -1.16   0.0  0.00  217.0  15.84   \n",
       "42850     A320            2 -9.12 -11.29 -6.96   0.0  0.00  280.0  18.25   \n",
       "42851  170/175            5 -9.12 -11.29 -6.96   0.0  0.00  280.0  18.25   \n",
       "42852     A319           27 -9.12 -11.29 -6.96   0.0  0.00  280.0  18.25   \n",
       "\n",
       "         pres  prediction  \n",
       "42843  1024.0         0.0  \n",
       "42844  1024.0         0.0  \n",
       "42845  1024.0         1.0  \n",
       "42846  1031.0         1.0  \n",
       "42847  1031.0         1.0  \n",
       "42848  1031.0         1.0  \n",
       "42849  1031.0         1.0  \n",
       "42850  1035.0         1.0  \n",
       "42851  1035.0         0.0  \n",
       "42852  1035.0         1.0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streaming_df = streaming_df.withColumn(\"id\", monotonically_increasing_id())\n",
    "predictions = predictions.withColumn(\"id\", monotonically_increasing_id())\n",
    "\n",
    "streaming_with_predictions = streaming_df.join(predictions.select(\"id\", \"prediction\"), on=\"id\", how=\"inner\")\n",
    "\n",
    "streaming_with_predictions = streaming_with_predictions.drop(\"id\")\n",
    "\n",
    "# Convert PySpark DataFrame to Pandas DataFrame\n",
    "prediction_df = streaming_with_predictions.toPandas()\n",
    "\n",
    "prediction_df = prediction_df.drop(columns=[\"dep_delay_tag\"])\n",
    "\n",
    "# Display the Pandas DataFrame\n",
    "prediction_df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e273d7d6",
   "metadata": {},
   "source": [
    "Defined a function `upload_s3_csv` to upload a Pandas DataFrame as a CSV file to a specified S3 bucket and folder, leveraging the AWS Boto3 library for seamless integration with AWS S3 storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cf6c1115-9b86-4a5a-9a2d-1bc2795e6d13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3_resource = boto3.Session().resource('s3')\n",
    "\n",
    "s3_bucket = 'big-data-team1-bucket'\n",
    "prediction_data_file = \"prediction_data.csv\"\n",
    "\n",
    "\n",
    "def upload_s3_csv(filename, folder, dataframe):\n",
    "    csv_buffer = StringIO()\n",
    "    dataframe.to_csv(csv_buffer, header=True, index=False)\n",
    "    s3_resource.Bucket(s3_bucket).Object(os.path.join(folder, filename)).put(Body=csv_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7117ab87",
   "metadata": {},
   "source": [
    "Uploaded the `prediction_df` DataFrame as a CSV file named `prediction_data.csv` to the `prediction-data` folder in the specified S3 bucket using the `upload_s3_csv` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d5b2c4aa-bc11-46b5-8491-a52d05c799bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "upload_s3_csv(prediction_data_file, \"prediction-data\", prediction_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
